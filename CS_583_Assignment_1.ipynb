{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Name: Prithvi Vadlamani**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**CWID: 10476457**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**email Address: pvadlam1@stevens.edu**"
      ],
      "metadata": {
        "id": "9gRv4x6Y_fw8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylUIQo1z29NJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense,Activation,Dropout \n",
        "from tensorflow.keras.layers import (\n",
        "    BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n",
        ")\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "ojnYAOum3EQq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d351eee-1822-4eff-8227-662effe7ac94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cLOVK9I3vNw",
        "outputId": "3fdd7b4b-4e88-4a52-ed44-df51f9edf062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.amax(x_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D0T-NJ55Uyk",
        "outputId": "7468c93f-85b8-4a2f-8f77-d5139b4471c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train/255 #scaling\n",
        "x_test = x_test/255 # scaling"
      ],
      "metadata": {
        "id": "66oTuby-6WWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = to_categorical(y_train)\n",
        "Y_test = to_categorical(y_test)\n",
        "y_train.shape\n",
        "Y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW6tuu6h6mGZ",
        "outputId": "accdaa9e-fff8-4f56-8d56-e0c62e883872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.flatten().reshape(60000, 28*28)\n",
        "x_test = x_test.flatten().reshape(10000, 28*28)"
      ],
      "metadata": {
        "id": "JDIvK5Bu7lW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "4BdgIn86_b_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg = LogisticRegression(penalty = 'l2', solver = 'saga')"
      ],
      "metadata": {
        "id": "LkJXpVol7xZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghHTepsz8nKO",
        "outputId": "ba7eb9b4-c4c9-4217-c0f8-6d0fb9862aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(solver='saga')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = log_reg.score(x_test, y_test)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kQWiqDA8sZB",
        "outputId": "8aacc7e2-d125-4330-9127-16df5b0183a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9261"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Networks"
      ],
      "metadata": {
        "id": "ltx1ziVwBhmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(500, input_dim = 784, activation = 'relu'))\n",
        "model.add(Dense(500, activation = 'relu'))\n",
        "model.add(Dense(10, activation = 'sigmoid'))\n"
      ],
      "metadata": {
        "id": "M9mlOgoy_9LH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFgYUnWrhpNT",
        "outputId": "51129932-7b24-42a9-8a26-f8ec18111a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 500)               392500    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 500)               250500    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                5010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 648,010\n",
            "Trainable params: 648,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss= 'categorical_crossentropy', optimizer = 'sgd', metrics = 'accuracy')"
      ],
      "metadata": {
        "id": "cybHeQXuCu58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_train, Y_train, validation_data = (x_test, Y_test), epochs=250, batch_size = 16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxL4SGgrDmcc",
        "outputId": "2e7fc856-d7c8-403f-e5b7-2498a9cc3c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "3750/3750 [==============================] - 13s 3ms/step - loss: 0.4276 - accuracy: 0.8861 - val_loss: 0.2367 - val_accuracy: 0.9321\n",
            "Epoch 2/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2107 - accuracy: 0.9394 - val_loss: 0.1728 - val_accuracy: 0.9493\n",
            "Epoch 3/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1590 - accuracy: 0.9538 - val_loss: 0.1444 - val_accuracy: 0.9590\n",
            "Epoch 4/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1278 - accuracy: 0.9636 - val_loss: 0.1214 - val_accuracy: 0.9646\n",
            "Epoch 5/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1058 - accuracy: 0.9698 - val_loss: 0.1068 - val_accuracy: 0.9682\n",
            "Epoch 6/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0896 - accuracy: 0.9747 - val_loss: 0.1018 - val_accuracy: 0.9694\n",
            "Epoch 7/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0774 - accuracy: 0.9779 - val_loss: 0.0899 - val_accuracy: 0.9717\n",
            "Epoch 8/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0674 - accuracy: 0.9810 - val_loss: 0.0899 - val_accuracy: 0.9728\n",
            "Epoch 9/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0593 - accuracy: 0.9836 - val_loss: 0.0815 - val_accuracy: 0.9749\n",
            "Epoch 10/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0525 - accuracy: 0.9859 - val_loss: 0.0772 - val_accuracy: 0.9761\n",
            "Epoch 11/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0458 - accuracy: 0.9873 - val_loss: 0.0737 - val_accuracy: 0.9759\n",
            "Epoch 12/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0406 - accuracy: 0.9890 - val_loss: 0.0722 - val_accuracy: 0.9770\n",
            "Epoch 13/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0363 - accuracy: 0.9904 - val_loss: 0.0705 - val_accuracy: 0.9785\n",
            "Epoch 14/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0324 - accuracy: 0.9917 - val_loss: 0.0684 - val_accuracy: 0.9791\n",
            "Epoch 15/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0285 - accuracy: 0.9930 - val_loss: 0.0710 - val_accuracy: 0.9780\n",
            "Epoch 16/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0256 - accuracy: 0.9940 - val_loss: 0.0652 - val_accuracy: 0.9799\n",
            "Epoch 17/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0226 - accuracy: 0.9948 - val_loss: 0.0682 - val_accuracy: 0.9786\n",
            "Epoch 18/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.0202 - accuracy: 0.9958 - val_loss: 0.0686 - val_accuracy: 0.9789\n",
            "Epoch 19/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0182 - accuracy: 0.9964 - val_loss: 0.0658 - val_accuracy: 0.9791\n",
            "Epoch 20/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.0161 - accuracy: 0.9971 - val_loss: 0.0650 - val_accuracy: 0.9801\n",
            "Epoch 21/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0146 - accuracy: 0.9974 - val_loss: 0.0664 - val_accuracy: 0.9795\n",
            "Epoch 22/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0131 - accuracy: 0.9980 - val_loss: 0.0689 - val_accuracy: 0.9789\n",
            "Epoch 23/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0117 - accuracy: 0.9985 - val_loss: 0.0660 - val_accuracy: 0.9796\n",
            "Epoch 24/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0106 - accuracy: 0.9987 - val_loss: 0.0659 - val_accuracy: 0.9794\n",
            "Epoch 25/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0095 - accuracy: 0.9991 - val_loss: 0.0647 - val_accuracy: 0.9799\n",
            "Epoch 26/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0086 - accuracy: 0.9992 - val_loss: 0.0653 - val_accuracy: 0.9800\n",
            "Epoch 27/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0079 - accuracy: 0.9994 - val_loss: 0.0662 - val_accuracy: 0.9800\n",
            "Epoch 28/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0072 - accuracy: 0.9993 - val_loss: 0.0663 - val_accuracy: 0.9807\n",
            "Epoch 29/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 0.0664 - val_accuracy: 0.9805\n",
            "Epoch 30/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0060 - accuracy: 0.9996 - val_loss: 0.0673 - val_accuracy: 0.9803\n",
            "Epoch 31/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0055 - accuracy: 0.9997 - val_loss: 0.0672 - val_accuracy: 0.9810\n",
            "Epoch 32/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0051 - accuracy: 0.9997 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
            "Epoch 33/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0047 - accuracy: 0.9997 - val_loss: 0.0694 - val_accuracy: 0.9805\n",
            "Epoch 34/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0043 - accuracy: 0.9998 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
            "Epoch 35/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.0041 - accuracy: 0.9998 - val_loss: 0.0691 - val_accuracy: 0.9807\n",
            "Epoch 36/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.0679 - val_accuracy: 0.9812\n",
            "Epoch 37/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.0711 - val_accuracy: 0.9796\n",
            "Epoch 38/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.0686 - val_accuracy: 0.9808\n",
            "Epoch 39/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9807\n",
            "Epoch 40/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9803\n",
            "Epoch 41/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0700 - val_accuracy: 0.9803\n",
            "Epoch 42/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9804\n",
            "Epoch 43/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 0.9809\n",
            "Epoch 44/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9806\n",
            "Epoch 45/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0714 - val_accuracy: 0.9810\n",
            "Epoch 46/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0708 - val_accuracy: 0.9805\n",
            "Epoch 47/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 0.9806\n",
            "Epoch 48/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0715 - val_accuracy: 0.9808\n",
            "Epoch 49/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0714 - val_accuracy: 0.9805\n",
            "Epoch 50/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0717 - val_accuracy: 0.9810\n",
            "Epoch 51/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0725 - val_accuracy: 0.9810\n",
            "Epoch 52/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9807\n",
            "Epoch 53/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0734 - val_accuracy: 0.9807\n",
            "Epoch 54/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0728 - val_accuracy: 0.9810\n",
            "Epoch 55/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 0.9810\n",
            "Epoch 56/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9809\n",
            "Epoch 57/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0734 - val_accuracy: 0.9809\n",
            "Epoch 58/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9805\n",
            "Epoch 59/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9807\n",
            "Epoch 60/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 0.9810\n",
            "Epoch 61/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 0.9811\n",
            "Epoch 62/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9808\n",
            "Epoch 63/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 0.9808\n",
            "Epoch 64/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 0.9809\n",
            "Epoch 65/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 0.9808\n",
            "Epoch 66/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9811\n",
            "Epoch 67/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 0.9805\n",
            "Epoch 68/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 0.9807\n",
            "Epoch 69/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 0.9806\n",
            "Epoch 70/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 9.8081e-04 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 0.9808\n",
            "Epoch 71/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 9.5921e-04 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 0.9809\n",
            "Epoch 72/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 9.3818e-04 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9809\n",
            "Epoch 73/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 9.0975e-04 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 0.9810\n",
            "Epoch 74/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 8.9343e-04 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9807\n",
            "Epoch 75/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 8.7199e-04 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 0.9805\n",
            "Epoch 76/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 8.5710e-04 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 0.9809\n",
            "Epoch 77/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 8.3956e-04 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 0.9810\n",
            "Epoch 78/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 8.1874e-04 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9808\n",
            "Epoch 79/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 7.9993e-04 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9811\n",
            "Epoch 80/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 7.8450e-04 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 0.9808\n",
            "Epoch 81/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 7.6750e-04 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9807\n",
            "Epoch 82/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 7.5337e-04 - accuracy: 1.0000 - val_loss: 0.0779 - val_accuracy: 0.9805\n",
            "Epoch 83/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 7.3749e-04 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 0.9807\n",
            "Epoch 84/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 7.2395e-04 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9809\n",
            "Epoch 85/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 7.0968e-04 - accuracy: 1.0000 - val_loss: 0.0779 - val_accuracy: 0.9809\n",
            "Epoch 86/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 6.9671e-04 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 0.9806\n",
            "Epoch 87/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 6.8477e-04 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 0.9805\n",
            "Epoch 88/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 6.7007e-04 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9809\n",
            "Epoch 89/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 6.6120e-04 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9810\n",
            "Epoch 90/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 6.4663e-04 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9810\n",
            "Epoch 91/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 6.3686e-04 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9810\n",
            "Epoch 92/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 6.2588e-04 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9808\n",
            "Epoch 93/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 6.1446e-04 - accuracy: 1.0000 - val_loss: 0.0792 - val_accuracy: 0.9809\n",
            "Epoch 94/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 6.0461e-04 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9808\n",
            "Epoch 95/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 5.9398e-04 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 0.9809\n",
            "Epoch 96/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 5.8568e-04 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9807\n",
            "Epoch 97/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 5.7522e-04 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 0.9808\n",
            "Epoch 98/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 5.6557e-04 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 0.9811\n",
            "Epoch 99/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 5.5715e-04 - accuracy: 1.0000 - val_loss: 0.0799 - val_accuracy: 0.9812\n",
            "Epoch 100/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 5.4833e-04 - accuracy: 1.0000 - val_loss: 0.0799 - val_accuracy: 0.9809\n",
            "Epoch 101/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 5.3972e-04 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 0.9808\n",
            "Epoch 102/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 5.3232e-04 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 0.9810\n",
            "Epoch 103/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 5.2380e-04 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 0.9808\n",
            "Epoch 104/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 5.1587e-04 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 0.9810\n",
            "Epoch 105/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 5.0836e-04 - accuracy: 1.0000 - val_loss: 0.0807 - val_accuracy: 0.9809\n",
            "Epoch 106/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 5.0165e-04 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9807\n",
            "Epoch 107/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 4.9565e-04 - accuracy: 1.0000 - val_loss: 0.0807 - val_accuracy: 0.9810\n",
            "Epoch 108/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 4.8749e-04 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9810\n",
            "Epoch 109/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 4.8014e-04 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 0.9809\n",
            "Epoch 110/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 4.7492e-04 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9810\n",
            "Epoch 111/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 4.6850e-04 - accuracy: 1.0000 - val_loss: 0.0814 - val_accuracy: 0.9810\n",
            "Epoch 112/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 4.6180e-04 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 0.9811\n",
            "Epoch 113/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 4.5503e-04 - accuracy: 1.0000 - val_loss: 0.0814 - val_accuracy: 0.9808\n",
            "Epoch 114/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 4.4926e-04 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 0.9809\n",
            "Epoch 115/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 4.4361e-04 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 0.9808\n",
            "Epoch 116/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 4.3811e-04 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 0.9810\n",
            "Epoch 117/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 4.3205e-04 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 0.9809\n",
            "Epoch 118/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 4.2600e-04 - accuracy: 1.0000 - val_loss: 0.0818 - val_accuracy: 0.9809\n",
            "Epoch 119/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 4.2184e-04 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 0.9808\n",
            "Epoch 120/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 4.1646e-04 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 0.9811\n",
            "Epoch 121/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 4.1133e-04 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 0.9810\n",
            "Epoch 122/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 4.0567e-04 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 0.9806\n",
            "Epoch 123/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 4.0044e-04 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 0.9811\n",
            "Epoch 124/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.9632e-04 - accuracy: 1.0000 - val_loss: 0.0823 - val_accuracy: 0.9810\n",
            "Epoch 125/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 3.9195e-04 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9809\n",
            "Epoch 126/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.8634e-04 - accuracy: 1.0000 - val_loss: 0.0825 - val_accuracy: 0.9809\n",
            "Epoch 127/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.8292e-04 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 0.9809\n",
            "Epoch 128/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.7824e-04 - accuracy: 1.0000 - val_loss: 0.0827 - val_accuracy: 0.9812\n",
            "Epoch 129/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.7289e-04 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 0.9808\n",
            "Epoch 130/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.6925e-04 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 0.9809\n",
            "Epoch 131/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.6569e-04 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9807\n",
            "Epoch 132/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.6165e-04 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 0.9809\n",
            "Epoch 133/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.5758e-04 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9810\n",
            "Epoch 134/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.5381e-04 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.9810\n",
            "Epoch 135/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.4947e-04 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.9810\n",
            "Epoch 136/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.4576e-04 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9808\n",
            "Epoch 137/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.4187e-04 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 0.9810\n",
            "Epoch 138/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.3879e-04 - accuracy: 1.0000 - val_loss: 0.0836 - val_accuracy: 0.9810\n",
            "Epoch 139/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.3463e-04 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9810\n",
            "Epoch 140/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.3109e-04 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9811\n",
            "Epoch 141/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.2827e-04 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9811\n",
            "Epoch 142/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.2510e-04 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9810\n",
            "Epoch 143/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 3.2150e-04 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 0.9809\n",
            "Epoch 144/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.1896e-04 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9810\n",
            "Epoch 145/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.1525e-04 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 0.9810\n",
            "Epoch 146/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.1223e-04 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 0.9809\n",
            "Epoch 147/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.0873e-04 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9811\n",
            "Epoch 148/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.0571e-04 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9810\n",
            "Epoch 149/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 3.0325e-04 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9811\n",
            "Epoch 150/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.9991e-04 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9812\n",
            "Epoch 151/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.9675e-04 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9810\n",
            "Epoch 152/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.9461e-04 - accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 0.9810\n",
            "Epoch 153/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.9182e-04 - accuracy: 1.0000 - val_loss: 0.0848 - val_accuracy: 0.9809\n",
            "Epoch 154/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.8909e-04 - accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 0.9811\n",
            "Epoch 155/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.8571e-04 - accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 0.9809\n",
            "Epoch 156/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.8348e-04 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9811\n",
            "Epoch 157/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.8119e-04 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9810\n",
            "Epoch 158/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.7875e-04 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9810\n",
            "Epoch 159/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.7586e-04 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9811\n",
            "Epoch 160/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.7379e-04 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9808\n",
            "Epoch 161/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.7139e-04 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9810\n",
            "Epoch 162/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.6878e-04 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9810\n",
            "Epoch 163/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.6656e-04 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9811\n",
            "Epoch 164/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.6418e-04 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9809\n",
            "Epoch 165/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.6194e-04 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9811\n",
            "Epoch 166/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.5974e-04 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9811\n",
            "Epoch 167/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.5771e-04 - accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 0.9811\n",
            "Epoch 168/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.5544e-04 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9811\n",
            "Epoch 169/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.5294e-04 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9812\n",
            "Epoch 170/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.5043e-04 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9809\n",
            "Epoch 171/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.4899e-04 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9811\n",
            "Epoch 172/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.4687e-04 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9811\n",
            "Epoch 173/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.4512e-04 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9810\n",
            "Epoch 174/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.4283e-04 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9812\n",
            "Epoch 175/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.4028e-04 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9811\n",
            "Epoch 176/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.3920e-04 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9808\n",
            "Epoch 177/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.3689e-04 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 0.9810\n",
            "Epoch 178/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.3552e-04 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9811\n",
            "Epoch 179/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.3383e-04 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9811\n",
            "Epoch 180/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.3151e-04 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9811\n",
            "Epoch 181/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.2976e-04 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9811\n",
            "Epoch 182/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.2817e-04 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9810\n",
            "Epoch 183/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.2629e-04 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9812\n",
            "Epoch 184/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.2489e-04 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9809\n",
            "Epoch 185/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.2292e-04 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9811\n",
            "Epoch 186/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.2138e-04 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 0.9812\n",
            "Epoch 187/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.1958e-04 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9810\n",
            "Epoch 188/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.1804e-04 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9811\n",
            "Epoch 189/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.1612e-04 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 0.9811\n",
            "Epoch 190/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.1523e-04 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9812\n",
            "Epoch 191/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.1337e-04 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9811\n",
            "Epoch 192/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.1152e-04 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9811\n",
            "Epoch 193/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.1022e-04 - accuracy: 1.0000 - val_loss: 0.0873 - val_accuracy: 0.9811\n",
            "Epoch 194/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.0891e-04 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9812\n",
            "Epoch 195/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.0736e-04 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9810\n",
            "Epoch 196/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.0565e-04 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9810\n",
            "Epoch 197/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.0438e-04 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9811\n",
            "Epoch 198/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 2.0302e-04 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9811\n",
            "Epoch 199/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.0139e-04 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9811\n",
            "Epoch 200/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 2.0051e-04 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9811\n",
            "Epoch 201/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.9885e-04 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9812\n",
            "Epoch 202/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.9749e-04 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9811\n",
            "Epoch 203/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.9623e-04 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9811\n",
            "Epoch 204/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.9480e-04 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9810\n",
            "Epoch 205/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.9357e-04 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9811\n",
            "Epoch 206/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.9216e-04 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9812\n",
            "Epoch 207/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.9077e-04 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9811\n",
            "Epoch 208/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.8967e-04 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9812\n",
            "Epoch 209/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.8840e-04 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9811\n",
            "Epoch 210/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.8702e-04 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9812\n",
            "Epoch 211/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.8611e-04 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9811\n",
            "Epoch 212/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.8486e-04 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9810\n",
            "Epoch 213/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.8335e-04 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9811\n",
            "Epoch 214/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.8254e-04 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9811\n",
            "Epoch 215/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.8123e-04 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9811\n",
            "Epoch 216/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 1.8020e-04 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9811\n",
            "Epoch 217/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.7892e-04 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9813\n",
            "Epoch 218/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.7781e-04 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9811\n",
            "Epoch 219/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.7681e-04 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9811\n",
            "Epoch 220/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.7585e-04 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9811\n",
            "Epoch 221/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.7463e-04 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9812\n",
            "Epoch 222/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.7335e-04 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9811\n",
            "Epoch 223/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.7249e-04 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9811\n",
            "Epoch 224/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.7133e-04 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9811\n",
            "Epoch 225/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.7041e-04 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9811\n",
            "Epoch 226/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.6939e-04 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9811\n",
            "Epoch 227/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.6804e-04 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9813\n",
            "Epoch 228/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.6738e-04 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9811\n",
            "Epoch 229/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.6622e-04 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9812\n",
            "Epoch 230/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.6542e-04 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9812\n",
            "Epoch 231/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.6437e-04 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9811\n",
            "Epoch 232/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.6338e-04 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9811\n",
            "Epoch 233/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.6247e-04 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9812\n",
            "Epoch 234/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.6131e-04 - accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 0.9813\n",
            "Epoch 235/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 1.6070e-04 - accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 0.9813\n",
            "Epoch 236/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.5959e-04 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9811\n",
            "Epoch 237/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.5846e-04 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9810\n",
            "Epoch 238/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.5774e-04 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9811\n",
            "Epoch 239/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.5704e-04 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9813\n",
            "Epoch 240/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.5585e-04 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9812\n",
            "Epoch 241/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.5513e-04 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9812\n",
            "Epoch 242/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.5443e-04 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9811\n",
            "Epoch 243/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.5347e-04 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9811\n",
            "Epoch 244/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.5259e-04 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9812\n",
            "Epoch 245/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.5178e-04 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9811\n",
            "Epoch 246/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.5098e-04 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9811\n",
            "Epoch 247/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.5012e-04 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 0.9811\n",
            "Epoch 248/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.4927e-04 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9813\n",
            "Epoch 249/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.4856e-04 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 0.9811\n",
            "Epoch 250/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.4770e-04 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "metadata": {
        "id": "cQ1f8BRED8NX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00ad1d2b-7c59-4427-e111-694643dff3d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(hist.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(hist.history[\"val_loss\"], label=\"test_loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "JSXitAsofxwQ",
        "outputId": "3557859d-e630-4468-ac99-33bd2f57dbe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3hU9b3v8fd3JjO5c0sClYsSBKx4KWAEraK19oJoxVup9lhLj304PbueY8+untKnraeyu8/Tdne7255SrO6Nu7V716dqqdTilmp1U1vlpqggIBGwBBRCuCYh1/mdP9YkmUxmkhBmWFmTz+t58syatX6z1ndl4JPf/Naatcw5h4iIBF/I7wJERCQzFOgiIjlCgS4ikiMU6CIiOUKBLiKSI/L82nB5ebmbOHGiX5sXEQmkjRs3HnTOVaRa5lugT5w4kQ0bNvi1eRGRQDKzd9Mt05CLiEiOUKCLiOQIBbqISI7wbQxdRHJPa2srNTU1NDU1+V1K4BUUFDB+/HgikUi/X6NAF5GMqampobS0lIkTJ2JmfpcTWM456urqqKmpobKyst+v05CLiGRMU1MTZWVlCvNTZGaUlZWd9CcdBbqIZJTCPDMG8nsMXKCv332If1y9ndb2mN+liIgMKoEL9FffPcz/+2M1LW0KdBGRRIEL9HDI+xjSrhtziEiSI0eO8NOf/vSkXzdv3jyOHDly0q9buHAhTzzxxEm/LlsCF+ih+LhSLKZAF5Hu0gV6W1tbr69btWoVI0aMyFZZp03gTlvMC8d76Ap0kUHt/t9t4a19xzK6zmljh/F/PnVe2uWLFy/mnXfeYfr06UQiEQoKChg5ciTbtm3j7bff5oYbbmDPnj00NTVx9913s2jRIqDr2lL19fVcc801XH755fzlL39h3LhxPPXUUxQWFvZZ2/PPP88999xDW1sbF198McuWLSM/P5/FixezcuVK8vLy+MQnPsEPfvADHn/8ce6//37C4TDDhw9nzZo1Gfn9BC7QO3roCnQRSfbd736XzZs3s2nTJl588UWuvfZaNm/e3Hku9/Llyxk1ahQnTpzg4osv5uabb6asrKzbOnbs2MGvfvUrHn74YRYsWMCTTz7J7bff3ut2m5qaWLhwIc8//zxTp07ljjvuYNmyZXzuc59jxYoVbNu2DTPrHNZZsmQJzz77LOPGjRvQUE86gQt0jaGLBENvPenTZdasWd2+mPPjH/+YFStWALBnzx527NjRI9ArKyuZPn06ABdddBG7d+/uczvbt2+nsrKSqVOnAvD5z3+epUuXctddd1FQUMCdd97Jddddx3XXXQfAZZddxsKFC1mwYAE33XRTJnYVCOAYelg9dBHpp+Li4s7pF198keeee46XX36Z119/nRkzZqT84k5+fn7ndDgc7nP8vTd5eXmsW7eOW265haeffpq5c+cC8OCDD/Kd73yHPXv2cNFFF1FXVzfgbXTbXkbWchqFQh0HRX0uREQGndLSUo4fP55y2dGjRxk5ciRFRUVs27aNV155JWPbPeecc9i9ezfV1dVMnjyZRx99lCuvvJL6+noaGxuZN28el112GZMmTQLgnXfeYfbs2cyePZtnnnmGPXv29PikMBCBC/Rw/DOFhlxEJFlZWRmXXXYZ559/PoWFhYwZM6Zz2dy5c3nwwQc599xzOeecc7jkkksytt2CggIeeeQRPv3pT3ceFP3Sl77EoUOHmD9/Pk1NTTjneOCBBwC499572bFjB845rr76aj70oQ9lpA5zPgVjVVWVG8gdi57atJe7H9vEc397JZNHl2ShMhEZqK1bt3Luuef6XUbOSPX7NLONzrmqVO37NYZuZnPNbLuZVZvZ4l7a3WxmzsxSbiwTOg6KxtRDFxHpps8hFzMLA0uBjwM1wHozW+mceyupXSlwN7A2G4V20EFRETndvvzlL/PnP/+527y7776bL3zhCz5VlFp/xtBnAdXOuZ0AZvYYMB94K6nd3wHfA+7NaIVJOk9bVKCLyGmydOlSv0vol/4MuYwD9iQ8r4nP62RmM4EJzrnf97YiM1tkZhvMbENtbe1JFwsKdBGRdE75PHQzCwEPAF/tq61z7iHnXJVzrqqiomJA2wvpi0UiIin1J9D3AhMSno+Pz+tQCpwPvGhmu4FLgJXZOjAa1sW5RERS6k+grwemmFmlmUWBW4GVHQudc0edc+XOuYnOuYnAK8D1zrmTPyexHzTkIiKSWp+B7pxrA+4CngW2Ar92zm0xsyVmdn22C0zWeXEuDbmISJKBXg8d4Ic//CGNjY29tpk4cSIHDx4c0PpPh36NoTvnVjnnpjrnznbO/X183n3OuZUp2n4kW71zSDgPXV/9F5Ek2Q70wU5f/ReR7HhmMbz/ZmbX+YEL4Jrvpl2ceD30j3/844wePZpf//rXNDc3c+ONN3L//ffT0NDAggULqKmpob29nW9961vs37+fffv2cdVVV1FeXs4LL7zQZykPPPAAy5cvB+CLX/wiX/nKV1Ku+zOf+UzKa6JnQ+ACXXcsEpF0Eq+Hvnr1ap544gnWrVuHc47rr7+eNWvWUFtby9ixY/n9772zrI8ePcrw4cN54IEHeOGFFygvL+9zOxs3buSRRx5h7dq1OOeYPXs2V155JTt37uyx7rq6upTXRM+GwAV6Xsjrorcp0EUGt1560qfD6tWrWb16NTNmzACgvr6eHTt2MGfOHL761a/yta99jeuuu445c+ac9Lpfeuklbrzxxs7L895000386U9/Yu7cuT3W3dbWlvKa6NkQuOuhhzqGXBToItIL5xxf//rX2bRpE5s2baK6upo777yTqVOn8uqrr3LBBRfwzW9+kyVLlmRsm6nWne6a6NkQuEDXxblEJJ3E66F/8pOfZPny5dTX1wOwd+9eDhw4wL59+ygqKuL222/n3nvv5dVXX+3x2r7MmTOH3/72tzQ2NtLQ0MCKFSuYM2dOynXX19dz9OhR5s2bxz/90z/x+uuvZ2fnCeCQiy7OJSLpJF4P/ZprruGzn/0sl156KQAlJSX88pe/pLq6mnvvvZdQKEQkEmHZsmUALFq0iLlz5zJ27Ng+D4rOnDmThQsXMmvWLMA7KDpjxgyeffbZHus+fvx4ymuiZ0Pgrof+Tm09V//jf/KjW6czf/q4vl8gIqeNroeeWVm5Hvpgoh66iEhqwRty0Vf/RSTLZs+eTXNzc7d5jz76KBdccIFPFfVP4AI9pIOiIoOacw6Lf5IOqrVrs3qfnn4ZyHB44IZc8uKBrvPQRQafgoIC6urqBhRG0sU5R11dHQUFBSf1uuD10PVNUZFBa/z48dTU1DDQG9hIl4KCAsaPH39SrwlcoGsMXWTwikQiVFZW+l3GkBW4IZfOs1yU5yIi3QQu0Du++q8hFxGR7gIX6GHdU1REJKXABXpIXywSEUkpcIHedcciBbqISKLgBbruKSoiklLgAj0UMsw05CIikixwgQ5eL12BLiLSXSADPRQyDbmIiCQJZKCHzXRQVEQkSTADPWS0x/yuQkRkcAlkoIdMl88VEUkWyED3eugKdBGRRMENdPXQRUS6CW6g63KLIiLdBDPQTT10EZFkgQz0UEinLYqIJAtkoGsMXUSkp2AGur76LyLSQyADPRQynYcuIpIkkIGuHrqISE+BDPSQvvovItJDIAM9HNJX/0VEkgU00EO0achFRKSbfgW6mc01s+1mVm1mi1Ms/5KZvWlmm8zsJTOblvlSu4RN9xQVEUnWZ6CbWRhYClwDTANuSxHY/+6cu8A5Nx34PvBAxitNoItziYj01J8e+iyg2jm30znXAjwGzE9s4Jw7lvC0GMhq2ob01X8RkR7y+tFmHLAn4XkNMDu5kZl9GfhbIAp8NNWKzGwRsAjgzDPPPNlaO4VDRkubTnMREUmUsYOizrmlzrmzga8B30zT5iHnXJVzrqqiomLA29JX/0VEeupPoO8FJiQ8Hx+fl85jwA2nUlRfQrqnqIhID/0J9PXAFDOrNLMocCuwMrGBmU1JeHotsCNzJfakHrqISE99jqE759rM7C7gWSAMLHfObTGzJcAG59xK4C4z+xjQChwGPp/NosMho003uBAR6aY/B0Vxzq0CViXNuy9h+u4M19WrsOniXCIiyQL6TVGdhy4ikiyQge5dPtfvKkREBpdABnrYUA9dRCRJIAM9pCEXEZEeAhnoOigqItJTMANdPXQRkR4CGei6p6iISE+BDPS8kOkGFyIiSQIZ6CHdJFpEpIdABno4pItziYgkC2yg6+JcIiLdBTLQvcvn+l2FiMjgEshAD4dQD11EJEkwA10HRUVEeghkoIdCBqADoyIiCQIZ6GHzAl3DLiIiXYIZ6OF4oKuHLiLSKZiBbgp0EZFkwQz0kIZcRESSBTLQQ6aDoiIiyQIZ6J09dAW6iEinQAZ6SEMuIiI9BC/Qj+7ljEPrMWL6+r+ISILgBfqbj/OxdXdSQIt66CIiCYIX6JEiAIpopr1dgS4i0iF4gR71Ar3Q1EMXEUkUvECPFAJQSLPOchERSRDAQC8GvEDXjaJFRLoEL9DjQy5Fph66iEii4AV6/KCohlxERLoLdKBryEVEpEsAA907KKohFxGR7oIX6FHvoGgBLeqhi4gkCF6gd36xqIk2fbFIRKRTAAM9YchFPXQRkU7BC/RQmFg437uWi8bQRUQ6BS/QgVheIUU009Dc7ncpIiKDRr8C3czmmtl2M6s2s8Uplv+tmb1lZm+Y2fNmdlbmS00QKaKQZhqa27K6GRGRIOkz0M0sDCwFrgGmAbeZ2bSkZq8BVc65C4EngO9nutBuosUUWjMNLQp0EZEO/emhzwKqnXM7nXMtwGPA/MQGzrkXnHON8aevAOMzW2Z3oWgRRTRTrx66iEin/gT6OGBPwvOa+Lx07gSeSbXAzBaZ2QYz21BbW9v/KpPXEy2i0Fo05CIikiCjB0XN7HagCviHVMudcw8556qcc1UVFRUD306kiJKQDoqKiCTK60ebvcCEhOfj4/O6MbOPAd8ArnTONWemvDSiRRRbi4ZcREQS9KeHvh6YYmaVZhYFbgVWJjYwsxnAz4DrnXMHMl9mkkixznIREUnSZ6A759qAu4Bnga3Ar51zW8xsiZldH2/2D0AJ8LiZbTKzlWlWlxmRQgp1UFREpJv+DLngnFsFrEqad1/C9McyXFfvosUUqIcuItJNIL8pSqSQqGumoUmBLiLSIaCBXkQIR0tzY99tRUSGiMAGOoBrafC5EBGRwSOYgR7tCnSnS+iKiABBDfR4Dz0v1kxzW8znYkREBodAB3qRznQREekUzECPD7kU6proIiKdghnoBcMBGGH1+nKRiEhcMAO9ZAwA5XZM10QXEYkLZqAXe1dqrOCIeugiInHBDPRwhPaCkVTYER0UFRGJC2agA7Hi0d6QiwJdRAQIcKBbyRgq7Aj1OstFRAQIcKCHSsdQwRGON7X6XYqIyKAQ7EAPHeVwfXZvjiQiEhSBDXRKxlBIC/XHj/hdiYjIoBDgQB8NQPvx/T4XIiIyOAQ+0EMN2b+FqYhIEAQ40L1vi0ZO1PpciIjI4BD4QC9srqM9pmuii4gEN9ALR9FueYy2wxxubPG7GhER3wU30EMhmgvHcIbVcahBgS4iEtxAB1pLxjHW6jioc9FFRIId6DZ8HGOpo65ePXQRkUAHemTkBMbYIQ7Xn/C7FBER3wU60PPLzyJq7Zw4/J7fpYiI+C7QgR4aPh6A9iM1PlciIuK/QAc68UAPH9vrcyEiIv4LeKCPAyCvYZ/PhYiI+C/YgV4wguZQIYWNGkMXEQl2oJvRkP8BRrUdoKlVdy4SkaEt2IEONA2vZLLtZd8RnbooIkNb4AM9Nvo8Ku093jt42O9SRER8FfhALxx/IWFz1O/Z7HcpIiK+CnygD6uc6U3sV6CLyNAW+ECPlE2ikQIKD231uxQREV8FPtAJhaiJTGRUww6/KxER8VXwAx2oLZ7KpJa34cQRv0sREfFNvwLdzOaa2XYzqzazxSmWX2Fmr5pZm5ndkvkye7fzrAUU0UTbSz8+3ZsWERk0+gx0MwsDS4FrgGnAbWY2LanZX4GFwL9nusD+GDHpIn7XfgmhtcvghE5fFJGhqT899FlAtXNup3OuBXgMmJ/YwDm32zn3BhDLQo19mjy6hF+0fYJQWyO8+7IfJYiI+K4/gT4O2JPwvCY+76SZ2SIz22BmG2praweyipQqy4vZzCTaLQw16zO2XhGRIDmtB0Wdcw8556qcc1UVFRUZW29BJMwHykZSE52sQBeRIas/gb4XmJDwfHx83qBydkUJr7kpsHcjtLf5XY6IyGmX148264EpZlaJF+S3Ap/NalUDMGVMCf+5YyI35DXC2gfhwgVQMtrvskQkKJyDWBu0t0B7a3y6FWKt3Z+3tyQta0toE39Muyz+/JxrYfxFGd+FPgPdOddmZncBzwJhYLlzbouZLQE2OOdWmtnFwApgJPApM7vfOXdexqvtxZTRJaxoOwcXzcNWf8Mbelnw89NZgsjQ1BmECaHV3tIzCHssSxN27S29LGtNHbLdnqcK5H68PnaaPtlbGIZP8CfQAZxzq4BVSfPuS5hejzcU45sLx4/gfcr43Uf/wPUHfgZbfwetTRAp8LMskVPnnBdSbc3xsEqYbmuOh1RzL9Mt3mN7S8J0a7xNx/KW9NtI12M93UEYyoNQBMIRbzociT/Pg3C0azqxTaQwviyxfcLreyxLeH2vyxLXlWK74Wj6ZWZZ+xX1K9CDYFJ5MaUFebxSG+H6Cz8NbzwGO1+Ec+b6XZoEWXsbtDZC64mEx8TpBu/RxSB/GLTUQ2MdNB+Hloaudi0NXvC5WNdPYsB2hmqKgI21ZnafQvGwyotCOD/+mDwdhaJib144VXBFk4Kqt2WJodjbsuSgTFqWxSDMFTkT6KGQMX3CCF776xH41BXef65tv1Og55L2Vu/yDq7dC8QTR7wABe95/X449p4XgHkFCT3QZi8UXAwaD0LDQe+xpRHy8r1eXEujF84tDV3TrSe8UB2ovEKIFkGk2HsMR8BCgHmPefEAzS/1psORNAEbX5aXnzQd7Xrs73Q4CqGcuOKHpJAzgQ4wY8IIfvJCNY2xEEUfvBbefBKu/BqMONPv0oampmNeD7WtqXtPtK3Jmz72HhytiQdpQo+3pTHe0z3k9XbbmuJDBE2AO7WaCoZDUTkUlXlB2t7ibSNaAiUfgGg8fCPxn2ixF/iRwvi8VI+FXkA3HYP8Eigc5XUoFJxymuVWoJ85kpiDN2qOcslV34C3noJnvga3/rs+rvVHaxMc3wfN9VBc0T1UT3Q8HvF6fMffg+PveyHb2gRNR71QixR6PeTD70JTPy+WFo4mhGeRF6jREiifDIWzvHnhPK+nW1wOoTBgUDAM8od76zCgeDQMG+v1YNtavN5tXoG3/libNxadF83Wb0/EdzkW6CMwg3W7DnHJpCnwkcXwh/vgtUdh5h1+l5d9sfi4bCgP9r0GhSPg4NteuOble0FYX+uFcWujN/Rw6B2vfWOd99MXC3tDHgUjYMQEb1ghL98LX+e89VoIxl/sfTLKL40PHeR3DRl0DCOUjPbahCPZ/92cjm2I+CynAn1EUZTzxg7jz9UH+Z9XT4FL74J3/gir7oVYO8z4nNfTC5qGg/D+m15Av/qoNxZcOAIO7fR6xuGoN1yxf4t3cbJoCbQcT7++wlHe0ED+MDjjQ/H1jYJh47webn6Jt838Uiga5S0rKvOmoyXe7zIU1qcekUEmgOnWu8vOLmf5n3fR2NJGUTQPbvpn+PXn4OmvwMZ/hRt+6gXZ1pUwa1H2e27vvwmbfwNX3OsNJYA3RHF0j9dz3rvBC+QDW70hjuJy2LMecN785uNw5F0vdKFrCKG1EUZWesHefsSbP3Wu12uuPwCVc7yDgcPGeqHd8YWIovJTP5UziH8URYaAnPuf+eHJ5fxszU7W7z7MlVMroKQCvvAMbFkBz/xvePhq78BY/fve47gq2LXGGzI4+6PeSpyDDcu95RecxOXd33wC1v8LXHGPd8pkpBA2/tzb1q41Xtjufwvqqr1hi0RFZVA4Enb9Cc66tOssjbLJ8KFbvSGM4+/BpKug9Azv9RpGEJEEORfoF08cSTQc4qUdtV6ggzc0cP5NMPFyePJOOLANRp0NL/xfb2ihvRkwmL/Ua/fH78DLP/HmNdbBWR+GMed7Qb9nLdRu9cK2fj9s/4/4Ndid9zwUgV/e5I0ju5h3IO+qb8JffuydKjf6PJg2H8qneME8bqa33kjRSZ4VoTMoRKQ7c+4UTwMboKqqKrdhw4asrPuO5et4t66BF+/5CJY8zuucN/ywdaUX7mVT4LZfwdP/C3b/yRvOaG+Bi74Atdvhr3/xXlc22Tvj48ShhJWZ90diVKU3PWoSTP8svLwUpl3vhbmLwZhp3nY15iwip8jMNjrnqlIty7keOsC88z/A4t+8yVvvHeO8scO7LzTzzrKYdoMX0B+cB8PHw395HN583Lta4/k3Q+UV3qlv+17zeuSbfwMTZnvDMmde6g2nRIu9MzeSffz+nvMU5iKSZTnZQ6+rb+biv3+Ov/nIZO755DlZ2YaIiB9666Hn5EBsWUk+l0wq4+k39uHXHywRkdMtJwMd4OaZ49ld18jaXYf6biwikgNyNtDnXXAGpQV5PLbur36XIiJyWuRsoBdGw9wwfRyrNr/P0cYMX35URGQQytlAB7h11gRa2mKseK3G71JERLIupwP9vLHDuWDccB5bv0cHR0Uk5+V0oIPXS9/2/nFe/ethv0sREcmqnA/0G6aPY2RRhB89X+13KSIiWZXzgV6cn8d/u/Js1rxdy8Z3dQqjiOSunA90gDsuPYvRpfnc99QW2tpjfpcjIpIVQyLQi6J5LJl/Hlv2HePhP+3yuxwRkawYEoEOMPf8M/jkeWP44XNvs+tgg9/liIhk3JAJdIAl888nmhdi8ZNvEIvpNEYRyS1DKtDHDCvgm9eey9pdh/jFy7v9LkdEJKOGVKADLKiawFXnVPDd/9jG5r1H/S5HRCRjhlygmxnfu+VCyorzWfiId2cjEZFcMOQCHWB0aQE//6+zaI857li+jtrjzX6XJCJyyoZkoANMHl3Cvyy8mP3Hmrjt4VfYd+SE3yWJiJySIRvoADPPHMm/fmEW+482MX/pn1m/W98kFZHgGtKBDnDJpDKe+O8fpjga5raHXmH5S7t0ZUYRCaQhH+gA53yglJX/43Ku+uBoljz9Fjct+4uu+yIigaNAjxtWEOFnt1/E92+5kL2HT3Dzspf5m3/byG59q1REAiLP7wIGk1DIWFA1gesuPIOH1+ziZ2ve4ZnN73P1B0dz+yVnMWdKBeGQ+V2miEhK5td4cVVVlduwYYMv2+6vA8ea+MXL7/LY+r9ysL6FkUURPvrBMVz1wQpmTRzF6GEFfpcoIkOMmW10zlWlXKZA71tzWzvPbz3A6i3v88dtBzjW1AbAWWVFXDxxFOePHcbk0aVMGVPC6NJ8zNSLF5HsOOVAN7O5wI+AMPDPzrnvJi3PB34BXATUAZ9xzu3ubZ1BCvREre0xtuw7xvpdh1i3+xAbdh/icGNr5/LSgjzOrvCCfURRhJFFUYbHH0cWRRheGGVkcYQRhVFGFEUoiIR93BsRCZpTCnQzCwNvAx8HaoD1wG3OubcS2vwNcKFz7ktmditwo3PuM72tN6iBnsw5R219M9X766murWfH/np2Hqynrr6Fw40tHG5spaUt/U01CiIhRhZFKYqGieaFieaFyA+HvMc87zGaFyIaDpEfCRENhzvn5cd/QmaEDMIhw8wIh7zn3nyLzyc+37q1D5kRircPW9Lr48u9+V3twyHvEgrhFOvu+HBiJE577Ts+t5h5yztmmHW16WofbxOf7vYYX3fX+qzzNSSsRyQX9Rbo/TkoOguods7tjK/sMWA+8FZCm/nAt+PTTwA/MTNzQ+CEbjNjdGkBo0sL+PDk8pRtTrS0c7ixhSONrRxpbOHIidZuzw83tnKipZ3mthgt7TFa2tppaGnjcGOMlvi85taOZV3zpHf9/oNC338sSPM3ItXsdH9QUs1O96cn1TrSt+1vZSdbQ6q22dm3dFKuN+17keJ3lon3rd8z+7/eu6+ewqc+NDb1Sk5BfwJ9HLAn4XkNMDtdG+dcm5kdBcqAg4mNzGwRsAjgzDPPHGDJwVMYDVMYLWTsiMKMrTMWc17At8dwMWh3jphzxGKOmIs/j8XnOWiPOZxz8fnE5zva4+07XtvuHC7ePta5zsT1EW+T8Np4247XOgDn6Phr7hydX9ZyHc87l7nONt5yl7S8ax4Jr+lq39Wmq33XCtMtT9we3daVft3JTqa7kqpvk+7lqdZ7MjWczHrTtU653jQrTlVb+rantt50O5d6vWn27aRqOLX1pqt3eGEk9YJTdFpPW3TOPQQ8BN6Qy+ncdq4JhYyCUFhj8CLSqT9fLNoLTEh4Pj4+L2UbM8sDhuMdHBURkdOkP4G+HphiZpVmFgVuBVYmtVkJfD4+fQvwx6Ewfi4iMpj0OeQSHxO/C3gW77TF5c65LWa2BNjgnFsJ/AvwqJlVA4fwQl9ERE6jfo2hO+dWAauS5t2XMN0EfDqzpYmIyMnQxblERHKEAl1EJEco0EVEcoQCXUQkR/h2tUUzqwXeHeDLy0n6FuoQMBT3GYbmfmufh4aB7vNZzrmKVAt8C/RTYWYb0l2cJlcNxX2Gobnf2uehIRv7rCEXEZEcoUAXEckRQQ30h/wuwAdDcZ9haO639nloyPg+B3IMXUREegpqD11ERJIo0EVEckTgAt3M5prZdjOrNrPFfteTLWa228zeNLNNZrYhPm+Umf3BzHbEH0f6XeepMLPlZnbAzDYnzEu5j+b5cfx9f8PMZvpX+cCl2edvm9ne+Hu9yczmJSz7enyft5vZJ/2p+tSY2QQze8HM3jKzLWZ2d3x+zr7Xvexzdt9rF7+dWBB+8C7f+w4wCYgCrwPT/K4rS/u6GyhPmvd9YHF8ejHwPb/rPMV9vAKYCWzuax+BecAzeLdtvARY63f9GdznbwP3pGg7Lf5vPB+ojP/bD/u9DwPY5zOAmfHpUrybzk/L5fe6l33O6nsdtApEd9UAAAIwSURBVB565w2rnXMtQMcNq4eK+cDP49M/B27wsZZT5pxbg3f9/ETp9nE+8AvneQUYYWZnnJ5KMyfNPqczH3jMOdfsnNsFVOP9HwgU59x7zrlX49PHga149yHO2fe6l31OJyPvddACPdUNq3v7JQWZA1ab2cb4zbUBxjjn3otPvw+M8ae0rEq3j7n+3t8VH15YnjCUlnP7bGYTgRnAWobIe520z5DF9zpogT6UXO6cmwlcA3zZzK5IXOi8z2k5fc7pUNjHuGXA2cB04D3gH/0tJzvMrAR4EviKc+5Y4rJcfa9T7HNW3+ugBXp/blidE5xze+OPB4AVeB+/9nd89Iw/HvCvwqxJt485+9475/Y759qdczHgYbo+aufMPptZBC/Y/s0595v47Jx+r1Ptc7bf66AFen9uWB14ZlZsZqUd08AngM10vxn354Gn/Kkwq9Lt40rgjvgZEJcARxM+rgda0vjwjXjvNXj7fKuZ5ZtZJTAFWHe66ztVZmZ49x3e6px7IGFRzr7X6fY56++130eDB3D0eB7eEeN3gG/4XU+W9nES3hHv14EtHfsJlAHPAzuA54BRftd6ivv5K7yPna14Y4Z3pttHvDMelsbf9zeBKr/rz+A+Pxrfpzfi/7HPSGj/jfg+bweu8bv+Ae7z5XjDKW8Am+I/83L5ve5ln7P6Xuur/yIiOSJoQy4iIpKGAl1EJEco0EVEcoQCXUQkRyjQRURyhAJdRCRHKNBFRHLE/wfHYKMJleXVoQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Networks with L2 and Dropout"
      ],
      "metadata": {
        "id": "Npjn-aOEgBvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_l2 = Sequential()\n",
        "model_l2.add(Dropout(0.2))\n",
        "model_l2.add(Dense(500, input_dim = 784, kernel_regularizer = l2(0.01), activation = 'relu'))\n",
        "model_l2.add(Dense(500, activation = 'relu'))\n",
        "model_l2.add(Dense(10, activation = 'sigmoid'))\n"
      ],
      "metadata": {
        "id": "SlV8F2Tif61u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_l2.compile(loss= 'categorical_crossentropy', optimizer = 'sgd', metrics = 'accuracy')"
      ],
      "metadata": {
        "id": "lrt9bEjthOJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist_l2 = model_l2.fit(x_train, Y_train, validation_data = (x_test, Y_test), epochs=250, batch_size = 16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVQMkuzAhiWJ",
        "outputId": "9b8aacb6-4b83-49fb-9810-0794c685d654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 3.7258 - accuracy: 0.8634 - val_loss: 1.7024 - val_accuracy: 0.9275\n",
            "Epoch 2/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 1.0635 - accuracy: 0.9208 - val_loss: 0.5997 - val_accuracy: 0.9386\n",
            "Epoch 3/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.4654 - accuracy: 0.9363 - val_loss: 0.3187 - val_accuracy: 0.9537\n",
            "Epoch 4/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.3119 - accuracy: 0.9449 - val_loss: 0.2527 - val_accuracy: 0.9570\n",
            "Epoch 5/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2664 - accuracy: 0.9496 - val_loss: 0.2217 - val_accuracy: 0.9609\n",
            "Epoch 6/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2438 - accuracy: 0.9542 - val_loss: 0.2135 - val_accuracy: 0.9610\n",
            "Epoch 7/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2330 - accuracy: 0.9559 - val_loss: 0.2053 - val_accuracy: 0.9655\n",
            "Epoch 8/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2249 - accuracy: 0.9583 - val_loss: 0.1903 - val_accuracy: 0.9682\n",
            "Epoch 9/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.2173 - accuracy: 0.9601 - val_loss: 0.1966 - val_accuracy: 0.9648\n",
            "Epoch 10/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.2148 - accuracy: 0.9610 - val_loss: 0.1923 - val_accuracy: 0.9676\n",
            "Epoch 11/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2120 - accuracy: 0.9612 - val_loss: 0.1848 - val_accuracy: 0.9693\n",
            "Epoch 12/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2094 - accuracy: 0.9613 - val_loss: 0.1887 - val_accuracy: 0.9669\n",
            "Epoch 13/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2058 - accuracy: 0.9629 - val_loss: 0.1908 - val_accuracy: 0.9675\n",
            "Epoch 14/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.2049 - accuracy: 0.9631 - val_loss: 0.1801 - val_accuracy: 0.9728\n",
            "Epoch 15/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2038 - accuracy: 0.9631 - val_loss: 0.1823 - val_accuracy: 0.9711\n",
            "Epoch 16/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2029 - accuracy: 0.9641 - val_loss: 0.1767 - val_accuracy: 0.9719\n",
            "Epoch 17/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2012 - accuracy: 0.9641 - val_loss: 0.1807 - val_accuracy: 0.9691\n",
            "Epoch 18/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2007 - accuracy: 0.9649 - val_loss: 0.1985 - val_accuracy: 0.9639\n",
            "Epoch 19/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2008 - accuracy: 0.9656 - val_loss: 0.1863 - val_accuracy: 0.9678\n",
            "Epoch 20/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1972 - accuracy: 0.9660 - val_loss: 0.1869 - val_accuracy: 0.9705\n",
            "Epoch 21/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1999 - accuracy: 0.9650 - val_loss: 0.1723 - val_accuracy: 0.9721\n",
            "Epoch 22/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1980 - accuracy: 0.9656 - val_loss: 0.1914 - val_accuracy: 0.9681\n",
            "Epoch 23/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1998 - accuracy: 0.9650 - val_loss: 0.1773 - val_accuracy: 0.9728\n",
            "Epoch 24/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1986 - accuracy: 0.9653 - val_loss: 0.1696 - val_accuracy: 0.9765\n",
            "Epoch 25/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1985 - accuracy: 0.9665 - val_loss: 0.2190 - val_accuracy: 0.9559\n",
            "Epoch 26/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1984 - accuracy: 0.9663 - val_loss: 0.2084 - val_accuracy: 0.9650\n",
            "Epoch 27/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1987 - accuracy: 0.9661 - val_loss: 0.1839 - val_accuracy: 0.9695\n",
            "Epoch 28/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2008 - accuracy: 0.9651 - val_loss: 0.1851 - val_accuracy: 0.9704\n",
            "Epoch 29/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.2004 - accuracy: 0.9659 - val_loss: 0.1753 - val_accuracy: 0.9725\n",
            "Epoch 30/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1994 - accuracy: 0.9658 - val_loss: 0.1729 - val_accuracy: 0.9750\n",
            "Epoch 31/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2022 - accuracy: 0.9651 - val_loss: 0.1827 - val_accuracy: 0.9724\n",
            "Epoch 32/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1985 - accuracy: 0.9669 - val_loss: 0.1857 - val_accuracy: 0.9680\n",
            "Epoch 33/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2001 - accuracy: 0.9666 - val_loss: 0.1870 - val_accuracy: 0.9676\n",
            "Epoch 34/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1976 - accuracy: 0.9670 - val_loss: 0.1740 - val_accuracy: 0.9741\n",
            "Epoch 35/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.2003 - accuracy: 0.9660 - val_loss: 0.1780 - val_accuracy: 0.9735\n",
            "Epoch 36/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2009 - accuracy: 0.9661 - val_loss: 0.1811 - val_accuracy: 0.9721\n",
            "Epoch 37/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1981 - accuracy: 0.9674 - val_loss: 0.1847 - val_accuracy: 0.9716\n",
            "Epoch 38/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1995 - accuracy: 0.9667 - val_loss: 0.1865 - val_accuracy: 0.9721\n",
            "Epoch 39/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1996 - accuracy: 0.9667 - val_loss: 0.1789 - val_accuracy: 0.9729\n",
            "Epoch 40/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1972 - accuracy: 0.9678 - val_loss: 0.1813 - val_accuracy: 0.9727\n",
            "Epoch 41/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.2017 - accuracy: 0.9666 - val_loss: 0.1728 - val_accuracy: 0.9768\n",
            "Epoch 42/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2004 - accuracy: 0.9670 - val_loss: 0.1956 - val_accuracy: 0.9682\n",
            "Epoch 43/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1976 - accuracy: 0.9675 - val_loss: 0.1758 - val_accuracy: 0.9754\n",
            "Epoch 44/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2003 - accuracy: 0.9671 - val_loss: 0.1709 - val_accuracy: 0.9775\n",
            "Epoch 45/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.2016 - accuracy: 0.9666 - val_loss: 0.1850 - val_accuracy: 0.9723\n",
            "Epoch 46/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2036 - accuracy: 0.9671 - val_loss: 0.1838 - val_accuracy: 0.9723\n",
            "Epoch 47/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1999 - accuracy: 0.9672 - val_loss: 0.1731 - val_accuracy: 0.9751\n",
            "Epoch 48/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2020 - accuracy: 0.9665 - val_loss: 0.1843 - val_accuracy: 0.9737\n",
            "Epoch 49/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2024 - accuracy: 0.9667 - val_loss: 0.2002 - val_accuracy: 0.9686\n",
            "Epoch 50/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1985 - accuracy: 0.9684 - val_loss: 0.1909 - val_accuracy: 0.9707\n",
            "Epoch 51/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1994 - accuracy: 0.9678 - val_loss: 0.1819 - val_accuracy: 0.9756\n",
            "Epoch 52/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1999 - accuracy: 0.9682 - val_loss: 0.1720 - val_accuracy: 0.9772\n",
            "Epoch 53/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2016 - accuracy: 0.9672 - val_loss: 0.1914 - val_accuracy: 0.9712\n",
            "Epoch 54/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2036 - accuracy: 0.9667 - val_loss: 0.1992 - val_accuracy: 0.9678\n",
            "Epoch 55/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2013 - accuracy: 0.9673 - val_loss: 0.1838 - val_accuracy: 0.9741\n",
            "Epoch 56/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2007 - accuracy: 0.9675 - val_loss: 0.1903 - val_accuracy: 0.9711\n",
            "Epoch 57/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2021 - accuracy: 0.9673 - val_loss: 0.1959 - val_accuracy: 0.9724\n",
            "Epoch 58/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2044 - accuracy: 0.9673 - val_loss: 0.1905 - val_accuracy: 0.9723\n",
            "Epoch 59/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2005 - accuracy: 0.9677 - val_loss: 0.1923 - val_accuracy: 0.9719\n",
            "Epoch 60/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2023 - accuracy: 0.9676 - val_loss: 0.1884 - val_accuracy: 0.9731\n",
            "Epoch 61/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2035 - accuracy: 0.9674 - val_loss: 0.2148 - val_accuracy: 0.9647\n",
            "Epoch 62/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2019 - accuracy: 0.9681 - val_loss: 0.1951 - val_accuracy: 0.9688\n",
            "Epoch 63/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.2018 - accuracy: 0.9686 - val_loss: 0.1903 - val_accuracy: 0.9704\n",
            "Epoch 64/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2010 - accuracy: 0.9681 - val_loss: 0.1850 - val_accuracy: 0.9736\n",
            "Epoch 65/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2025 - accuracy: 0.9673 - val_loss: 0.1883 - val_accuracy: 0.9736\n",
            "Epoch 66/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2031 - accuracy: 0.9685 - val_loss: 0.1788 - val_accuracy: 0.9739\n",
            "Epoch 67/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2004 - accuracy: 0.9678 - val_loss: 0.1845 - val_accuracy: 0.9736\n",
            "Epoch 68/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2041 - accuracy: 0.9669 - val_loss: 0.1844 - val_accuracy: 0.9743\n",
            "Epoch 69/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2037 - accuracy: 0.9676 - val_loss: 0.2104 - val_accuracy: 0.9660\n",
            "Epoch 70/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1973 - accuracy: 0.9690 - val_loss: 0.1890 - val_accuracy: 0.9713\n",
            "Epoch 71/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2025 - accuracy: 0.9678 - val_loss: 0.2143 - val_accuracy: 0.9634\n",
            "Epoch 72/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2012 - accuracy: 0.9684 - val_loss: 0.1867 - val_accuracy: 0.9734\n",
            "Epoch 73/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2032 - accuracy: 0.9678 - val_loss: 0.1853 - val_accuracy: 0.9744\n",
            "Epoch 74/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2027 - accuracy: 0.9678 - val_loss: 0.1967 - val_accuracy: 0.9724\n",
            "Epoch 75/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2009 - accuracy: 0.9685 - val_loss: 0.1919 - val_accuracy: 0.9703\n",
            "Epoch 76/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2031 - accuracy: 0.9682 - val_loss: 0.1793 - val_accuracy: 0.9756\n",
            "Epoch 77/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2020 - accuracy: 0.9684 - val_loss: 0.1734 - val_accuracy: 0.9768\n",
            "Epoch 78/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2034 - accuracy: 0.9672 - val_loss: 0.2085 - val_accuracy: 0.9659\n",
            "Epoch 79/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2014 - accuracy: 0.9689 - val_loss: 0.1931 - val_accuracy: 0.9696\n",
            "Epoch 80/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2003 - accuracy: 0.9688 - val_loss: 0.1846 - val_accuracy: 0.9738\n",
            "Epoch 81/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.2007 - accuracy: 0.9689 - val_loss: 0.1844 - val_accuracy: 0.9725\n",
            "Epoch 82/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2010 - accuracy: 0.9686 - val_loss: 0.2080 - val_accuracy: 0.9681\n",
            "Epoch 83/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2010 - accuracy: 0.9690 - val_loss: 0.1854 - val_accuracy: 0.9730\n",
            "Epoch 84/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2046 - accuracy: 0.9677 - val_loss: 0.1896 - val_accuracy: 0.9727\n",
            "Epoch 85/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2040 - accuracy: 0.9675 - val_loss: 0.1804 - val_accuracy: 0.9769\n",
            "Epoch 86/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2038 - accuracy: 0.9673 - val_loss: 0.1804 - val_accuracy: 0.9756\n",
            "Epoch 87/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2028 - accuracy: 0.9681 - val_loss: 0.1840 - val_accuracy: 0.9748\n",
            "Epoch 88/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2009 - accuracy: 0.9686 - val_loss: 0.2241 - val_accuracy: 0.9615\n",
            "Epoch 89/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2041 - accuracy: 0.9674 - val_loss: 0.1856 - val_accuracy: 0.9721\n",
            "Epoch 90/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2004 - accuracy: 0.9696 - val_loss: 0.1870 - val_accuracy: 0.9713\n",
            "Epoch 91/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1973 - accuracy: 0.9697 - val_loss: 0.2082 - val_accuracy: 0.9657\n",
            "Epoch 92/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2026 - accuracy: 0.9682 - val_loss: 0.1886 - val_accuracy: 0.9750\n",
            "Epoch 93/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2011 - accuracy: 0.9691 - val_loss: 0.2262 - val_accuracy: 0.9590\n",
            "Epoch 94/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2040 - accuracy: 0.9682 - val_loss: 0.1829 - val_accuracy: 0.9739\n",
            "Epoch 95/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1997 - accuracy: 0.9686 - val_loss: 0.1998 - val_accuracy: 0.9696\n",
            "Epoch 96/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2010 - accuracy: 0.9686 - val_loss: 0.1912 - val_accuracy: 0.9713\n",
            "Epoch 97/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2014 - accuracy: 0.9686 - val_loss: 0.1972 - val_accuracy: 0.9707\n",
            "Epoch 98/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1994 - accuracy: 0.9690 - val_loss: 0.1860 - val_accuracy: 0.9730\n",
            "Epoch 99/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1994 - accuracy: 0.9690 - val_loss: 0.1933 - val_accuracy: 0.9725\n",
            "Epoch 100/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1982 - accuracy: 0.9693 - val_loss: 0.2053 - val_accuracy: 0.9677\n",
            "Epoch 101/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.2006 - accuracy: 0.9680 - val_loss: 0.2023 - val_accuracy: 0.9672\n",
            "Epoch 102/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.2009 - accuracy: 0.9690 - val_loss: 0.2076 - val_accuracy: 0.9644\n",
            "Epoch 103/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2001 - accuracy: 0.9681 - val_loss: 0.2027 - val_accuracy: 0.9679\n",
            "Epoch 104/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1994 - accuracy: 0.9693 - val_loss: 0.1776 - val_accuracy: 0.9758\n",
            "Epoch 105/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1991 - accuracy: 0.9688 - val_loss: 0.1766 - val_accuracy: 0.9762\n",
            "Epoch 106/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1977 - accuracy: 0.9692 - val_loss: 0.1749 - val_accuracy: 0.9766\n",
            "Epoch 107/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2022 - accuracy: 0.9682 - val_loss: 0.1747 - val_accuracy: 0.9762\n",
            "Epoch 108/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1990 - accuracy: 0.9694 - val_loss: 0.1942 - val_accuracy: 0.9714\n",
            "Epoch 109/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1962 - accuracy: 0.9691 - val_loss: 0.1876 - val_accuracy: 0.9734\n",
            "Epoch 110/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1974 - accuracy: 0.9689 - val_loss: 0.1922 - val_accuracy: 0.9714\n",
            "Epoch 111/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2019 - accuracy: 0.9681 - val_loss: 0.1800 - val_accuracy: 0.9759\n",
            "Epoch 112/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2018 - accuracy: 0.9674 - val_loss: 0.1990 - val_accuracy: 0.9706\n",
            "Epoch 113/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2024 - accuracy: 0.9680 - val_loss: 0.1798 - val_accuracy: 0.9753\n",
            "Epoch 114/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2008 - accuracy: 0.9682 - val_loss: 0.1855 - val_accuracy: 0.9733\n",
            "Epoch 115/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2000 - accuracy: 0.9693 - val_loss: 0.1833 - val_accuracy: 0.9725\n",
            "Epoch 116/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2008 - accuracy: 0.9687 - val_loss: 0.1787 - val_accuracy: 0.9760\n",
            "Epoch 117/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.2002 - accuracy: 0.9686 - val_loss: 0.1894 - val_accuracy: 0.9728\n",
            "Epoch 118/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1990 - accuracy: 0.9686 - val_loss: 0.2160 - val_accuracy: 0.9649\n",
            "Epoch 119/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1983 - accuracy: 0.9698 - val_loss: 0.2004 - val_accuracy: 0.9681\n",
            "Epoch 120/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1971 - accuracy: 0.9694 - val_loss: 0.1693 - val_accuracy: 0.9782\n",
            "Epoch 121/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1986 - accuracy: 0.9694 - val_loss: 0.1824 - val_accuracy: 0.9763\n",
            "Epoch 122/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1975 - accuracy: 0.9689 - val_loss: 0.1796 - val_accuracy: 0.9752\n",
            "Epoch 123/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1991 - accuracy: 0.9686 - val_loss: 0.1853 - val_accuracy: 0.9737\n",
            "Epoch 124/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1984 - accuracy: 0.9692 - val_loss: 0.1777 - val_accuracy: 0.9774\n",
            "Epoch 125/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2021 - accuracy: 0.9684 - val_loss: 0.1892 - val_accuracy: 0.9747\n",
            "Epoch 126/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1985 - accuracy: 0.9685 - val_loss: 0.2163 - val_accuracy: 0.9623\n",
            "Epoch 127/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1992 - accuracy: 0.9681 - val_loss: 0.1894 - val_accuracy: 0.9730\n",
            "Epoch 128/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.2007 - accuracy: 0.9688 - val_loss: 0.1840 - val_accuracy: 0.9742\n",
            "Epoch 129/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1977 - accuracy: 0.9691 - val_loss: 0.1818 - val_accuracy: 0.9755\n",
            "Epoch 130/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1961 - accuracy: 0.9703 - val_loss: 0.2052 - val_accuracy: 0.9664\n",
            "Epoch 131/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1977 - accuracy: 0.9692 - val_loss: 0.1744 - val_accuracy: 0.9772\n",
            "Epoch 132/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1958 - accuracy: 0.9699 - val_loss: 0.1964 - val_accuracy: 0.9708\n",
            "Epoch 133/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1996 - accuracy: 0.9691 - val_loss: 0.1956 - val_accuracy: 0.9694\n",
            "Epoch 134/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1974 - accuracy: 0.9699 - val_loss: 0.1774 - val_accuracy: 0.9737\n",
            "Epoch 135/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1913 - accuracy: 0.9710 - val_loss: 0.1808 - val_accuracy: 0.9738\n",
            "Epoch 136/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1960 - accuracy: 0.9689 - val_loss: 0.1814 - val_accuracy: 0.9764\n",
            "Epoch 137/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1961 - accuracy: 0.9697 - val_loss: 0.1759 - val_accuracy: 0.9749\n",
            "Epoch 138/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1957 - accuracy: 0.9701 - val_loss: 0.1718 - val_accuracy: 0.9772\n",
            "Epoch 139/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1967 - accuracy: 0.9691 - val_loss: 0.1816 - val_accuracy: 0.9740\n",
            "Epoch 140/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1982 - accuracy: 0.9684 - val_loss: 0.1824 - val_accuracy: 0.9743\n",
            "Epoch 141/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1933 - accuracy: 0.9706 - val_loss: 0.1752 - val_accuracy: 0.9744\n",
            "Epoch 142/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1954 - accuracy: 0.9692 - val_loss: 0.1789 - val_accuracy: 0.9760\n",
            "Epoch 143/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1953 - accuracy: 0.9692 - val_loss: 0.1890 - val_accuracy: 0.9706\n",
            "Epoch 144/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1936 - accuracy: 0.9700 - val_loss: 0.1765 - val_accuracy: 0.9754\n",
            "Epoch 145/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1957 - accuracy: 0.9696 - val_loss: 0.1825 - val_accuracy: 0.9727\n",
            "Epoch 146/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1962 - accuracy: 0.9693 - val_loss: 0.1824 - val_accuracy: 0.9750\n",
            "Epoch 147/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1964 - accuracy: 0.9699 - val_loss: 0.1845 - val_accuracy: 0.9712\n",
            "Epoch 148/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1944 - accuracy: 0.9699 - val_loss: 0.1867 - val_accuracy: 0.9754\n",
            "Epoch 149/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1931 - accuracy: 0.9703 - val_loss: 0.1898 - val_accuracy: 0.9696\n",
            "Epoch 150/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1960 - accuracy: 0.9693 - val_loss: 0.1722 - val_accuracy: 0.9770\n",
            "Epoch 151/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1952 - accuracy: 0.9696 - val_loss: 0.1823 - val_accuracy: 0.9745\n",
            "Epoch 152/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1935 - accuracy: 0.9696 - val_loss: 0.2101 - val_accuracy: 0.9649\n",
            "Epoch 153/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1945 - accuracy: 0.9696 - val_loss: 0.2033 - val_accuracy: 0.9672\n",
            "Epoch 154/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1960 - accuracy: 0.9686 - val_loss: 0.1718 - val_accuracy: 0.9777\n",
            "Epoch 155/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1926 - accuracy: 0.9700 - val_loss: 0.1955 - val_accuracy: 0.9683\n",
            "Epoch 156/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1917 - accuracy: 0.9704 - val_loss: 0.1710 - val_accuracy: 0.9772\n",
            "Epoch 157/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1941 - accuracy: 0.9698 - val_loss: 0.1906 - val_accuracy: 0.9710\n",
            "Epoch 158/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1935 - accuracy: 0.9700 - val_loss: 0.1734 - val_accuracy: 0.9760\n",
            "Epoch 159/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1900 - accuracy: 0.9708 - val_loss: 0.1743 - val_accuracy: 0.9767\n",
            "Epoch 160/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1927 - accuracy: 0.9695 - val_loss: 0.1805 - val_accuracy: 0.9738\n",
            "Epoch 161/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1920 - accuracy: 0.9706 - val_loss: 0.1803 - val_accuracy: 0.9735\n",
            "Epoch 162/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1931 - accuracy: 0.9695 - val_loss: 0.1708 - val_accuracy: 0.9787\n",
            "Epoch 163/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1929 - accuracy: 0.9702 - val_loss: 0.1872 - val_accuracy: 0.9723\n",
            "Epoch 164/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1918 - accuracy: 0.9704 - val_loss: 0.1713 - val_accuracy: 0.9755\n",
            "Epoch 165/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1931 - accuracy: 0.9696 - val_loss: 0.1925 - val_accuracy: 0.9710\n",
            "Epoch 166/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1908 - accuracy: 0.9702 - val_loss: 0.1729 - val_accuracy: 0.9752\n",
            "Epoch 167/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1937 - accuracy: 0.9703 - val_loss: 0.2016 - val_accuracy: 0.9654\n",
            "Epoch 168/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1924 - accuracy: 0.9703 - val_loss: 0.1762 - val_accuracy: 0.9765\n",
            "Epoch 169/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1891 - accuracy: 0.9711 - val_loss: 0.1669 - val_accuracy: 0.9799\n",
            "Epoch 170/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1918 - accuracy: 0.9704 - val_loss: 0.1710 - val_accuracy: 0.9772\n",
            "Epoch 171/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1883 - accuracy: 0.9708 - val_loss: 0.1740 - val_accuracy: 0.9757\n",
            "Epoch 172/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1912 - accuracy: 0.9705 - val_loss: 0.1891 - val_accuracy: 0.9739\n",
            "Epoch 173/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1898 - accuracy: 0.9711 - val_loss: 0.1840 - val_accuracy: 0.9751\n",
            "Epoch 174/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1926 - accuracy: 0.9707 - val_loss: 0.1906 - val_accuracy: 0.9700\n",
            "Epoch 175/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1889 - accuracy: 0.9706 - val_loss: 0.1775 - val_accuracy: 0.9760\n",
            "Epoch 176/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1888 - accuracy: 0.9711 - val_loss: 0.1888 - val_accuracy: 0.9700\n",
            "Epoch 177/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1898 - accuracy: 0.9706 - val_loss: 0.1862 - val_accuracy: 0.9723\n",
            "Epoch 178/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1905 - accuracy: 0.9703 - val_loss: 0.1974 - val_accuracy: 0.9702\n",
            "Epoch 179/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1877 - accuracy: 0.9712 - val_loss: 0.1756 - val_accuracy: 0.9763\n",
            "Epoch 180/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1910 - accuracy: 0.9705 - val_loss: 0.1977 - val_accuracy: 0.9667\n",
            "Epoch 181/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1907 - accuracy: 0.9703 - val_loss: 0.1823 - val_accuracy: 0.9736\n",
            "Epoch 182/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1905 - accuracy: 0.9704 - val_loss: 0.1696 - val_accuracy: 0.9768\n",
            "Epoch 183/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1924 - accuracy: 0.9693 - val_loss: 0.1830 - val_accuracy: 0.9732\n",
            "Epoch 184/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1907 - accuracy: 0.9700 - val_loss: 0.1840 - val_accuracy: 0.9731\n",
            "Epoch 185/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1882 - accuracy: 0.9710 - val_loss: 0.1875 - val_accuracy: 0.9717\n",
            "Epoch 186/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1924 - accuracy: 0.9699 - val_loss: 0.1793 - val_accuracy: 0.9750\n",
            "Epoch 187/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1913 - accuracy: 0.9698 - val_loss: 0.1780 - val_accuracy: 0.9742\n",
            "Epoch 188/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1887 - accuracy: 0.9712 - val_loss: 0.1991 - val_accuracy: 0.9691\n",
            "Epoch 189/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1871 - accuracy: 0.9706 - val_loss: 0.1719 - val_accuracy: 0.9761\n",
            "Epoch 190/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1852 - accuracy: 0.9717 - val_loss: 0.1849 - val_accuracy: 0.9724\n",
            "Epoch 191/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1896 - accuracy: 0.9704 - val_loss: 0.1761 - val_accuracy: 0.9750\n",
            "Epoch 192/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1852 - accuracy: 0.9714 - val_loss: 0.1821 - val_accuracy: 0.9722\n",
            "Epoch 193/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1886 - accuracy: 0.9707 - val_loss: 0.2139 - val_accuracy: 0.9655\n",
            "Epoch 194/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1847 - accuracy: 0.9721 - val_loss: 0.1607 - val_accuracy: 0.9788\n",
            "Epoch 195/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1858 - accuracy: 0.9714 - val_loss: 0.1723 - val_accuracy: 0.9763\n",
            "Epoch 196/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1876 - accuracy: 0.9707 - val_loss: 0.1758 - val_accuracy: 0.9752\n",
            "Epoch 197/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1856 - accuracy: 0.9713 - val_loss: 0.1746 - val_accuracy: 0.9772\n",
            "Epoch 198/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1886 - accuracy: 0.9701 - val_loss: 0.1666 - val_accuracy: 0.9772\n",
            "Epoch 199/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1844 - accuracy: 0.9714 - val_loss: 0.1732 - val_accuracy: 0.9757\n",
            "Epoch 200/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1881 - accuracy: 0.9705 - val_loss: 0.1651 - val_accuracy: 0.9779\n",
            "Epoch 201/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1885 - accuracy: 0.9705 - val_loss: 0.1701 - val_accuracy: 0.9771\n",
            "Epoch 202/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1855 - accuracy: 0.9721 - val_loss: 0.2012 - val_accuracy: 0.9690\n",
            "Epoch 203/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1850 - accuracy: 0.9714 - val_loss: 0.1740 - val_accuracy: 0.9756\n",
            "Epoch 204/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1855 - accuracy: 0.9707 - val_loss: 0.1739 - val_accuracy: 0.9739\n",
            "Epoch 205/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1830 - accuracy: 0.9721 - val_loss: 0.1890 - val_accuracy: 0.9696\n",
            "Epoch 206/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1858 - accuracy: 0.9707 - val_loss: 0.1957 - val_accuracy: 0.9692\n",
            "Epoch 207/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1852 - accuracy: 0.9718 - val_loss: 0.2419 - val_accuracy: 0.9544\n",
            "Epoch 208/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1861 - accuracy: 0.9713 - val_loss: 0.1743 - val_accuracy: 0.9766\n",
            "Epoch 209/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1860 - accuracy: 0.9712 - val_loss: 0.1731 - val_accuracy: 0.9746\n",
            "Epoch 210/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1842 - accuracy: 0.9718 - val_loss: 0.1838 - val_accuracy: 0.9724\n",
            "Epoch 211/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1857 - accuracy: 0.9710 - val_loss: 0.1730 - val_accuracy: 0.9751\n",
            "Epoch 212/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1813 - accuracy: 0.9719 - val_loss: 0.1762 - val_accuracy: 0.9752\n",
            "Epoch 213/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1860 - accuracy: 0.9709 - val_loss: 0.1749 - val_accuracy: 0.9745\n",
            "Epoch 214/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1862 - accuracy: 0.9715 - val_loss: 0.1588 - val_accuracy: 0.9797\n",
            "Epoch 215/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1828 - accuracy: 0.9714 - val_loss: 0.1761 - val_accuracy: 0.9724\n",
            "Epoch 216/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1824 - accuracy: 0.9722 - val_loss: 0.1678 - val_accuracy: 0.9760\n",
            "Epoch 217/250\n",
            "3750/3750 [==============================] - 10s 3ms/step - loss: 0.1820 - accuracy: 0.9717 - val_loss: 0.1878 - val_accuracy: 0.9705\n",
            "Epoch 218/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1822 - accuracy: 0.9710 - val_loss: 0.1861 - val_accuracy: 0.9716\n",
            "Epoch 219/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1838 - accuracy: 0.9718 - val_loss: 0.1762 - val_accuracy: 0.9745\n",
            "Epoch 220/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1824 - accuracy: 0.9717 - val_loss: 0.1747 - val_accuracy: 0.9750\n",
            "Epoch 221/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1836 - accuracy: 0.9717 - val_loss: 0.1743 - val_accuracy: 0.9762\n",
            "Epoch 222/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1837 - accuracy: 0.9717 - val_loss: 0.1778 - val_accuracy: 0.9738\n",
            "Epoch 223/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1812 - accuracy: 0.9723 - val_loss: 0.1614 - val_accuracy: 0.9788\n",
            "Epoch 224/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1835 - accuracy: 0.9715 - val_loss: 0.1647 - val_accuracy: 0.9793\n",
            "Epoch 225/250\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1826 - accuracy: 0.9722 - val_loss: 0.1949 - val_accuracy: 0.9684\n",
            "Epoch 226/250\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1833 - accuracy: 0.9722 - val_loss: 0.1778 - val_accuracy: 0.9740\n",
            "Epoch 227/250\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1810 - accuracy: 0.9726 - val_loss: 0.1713 - val_accuracy: 0.9766\n",
            "Epoch 228/250\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1828 - accuracy: 0.9711 - val_loss: 0.1676 - val_accuracy: 0.9774\n",
            "Epoch 229/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1831 - accuracy: 0.9712 - val_loss: 0.1685 - val_accuracy: 0.9771\n",
            "Epoch 230/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1805 - accuracy: 0.9726 - val_loss: 0.1686 - val_accuracy: 0.9768\n",
            "Epoch 231/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1800 - accuracy: 0.9720 - val_loss: 0.1750 - val_accuracy: 0.9728\n",
            "Epoch 232/250\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1812 - accuracy: 0.9714 - val_loss: 0.1738 - val_accuracy: 0.9740\n",
            "Epoch 233/250\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1820 - accuracy: 0.9716 - val_loss: 0.1668 - val_accuracy: 0.9774\n",
            "Epoch 234/250\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1817 - accuracy: 0.9707 - val_loss: 0.1792 - val_accuracy: 0.9755\n",
            "Epoch 235/250\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1809 - accuracy: 0.9718 - val_loss: 0.1647 - val_accuracy: 0.9792\n",
            "Epoch 236/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1796 - accuracy: 0.9724 - val_loss: 0.1984 - val_accuracy: 0.9646\n",
            "Epoch 237/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1781 - accuracy: 0.9723 - val_loss: 0.1663 - val_accuracy: 0.9768\n",
            "Epoch 238/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1809 - accuracy: 0.9718 - val_loss: 0.1728 - val_accuracy: 0.9757\n",
            "Epoch 239/250\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1790 - accuracy: 0.9725 - val_loss: 0.1702 - val_accuracy: 0.9768\n",
            "Epoch 240/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1808 - accuracy: 0.9720 - val_loss: 0.1772 - val_accuracy: 0.9727\n",
            "Epoch 241/250\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1773 - accuracy: 0.9728 - val_loss: 0.1681 - val_accuracy: 0.9764\n",
            "Epoch 242/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1816 - accuracy: 0.9717 - val_loss: 0.1694 - val_accuracy: 0.9757\n",
            "Epoch 243/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1817 - accuracy: 0.9720 - val_loss: 0.1761 - val_accuracy: 0.9745\n",
            "Epoch 244/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1780 - accuracy: 0.9729 - val_loss: 0.1719 - val_accuracy: 0.9744\n",
            "Epoch 245/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1777 - accuracy: 0.9717 - val_loss: 0.1873 - val_accuracy: 0.9714\n",
            "Epoch 246/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1806 - accuracy: 0.9724 - val_loss: 0.1608 - val_accuracy: 0.9781\n",
            "Epoch 247/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1769 - accuracy: 0.9729 - val_loss: 0.1610 - val_accuracy: 0.9783\n",
            "Epoch 248/250\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.1771 - accuracy: 0.9727 - val_loss: 0.1796 - val_accuracy: 0.9720\n",
            "Epoch 249/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1797 - accuracy: 0.9725 - val_loss: 0.1726 - val_accuracy: 0.9746\n",
            "Epoch 250/250\n",
            "3750/3750 [==============================] - 11s 3ms/step - loss: 0.1773 - accuracy: 0.9724 - val_loss: 0.1729 - val_accuracy: 0.9752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(hist_l2.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(hist_l2.history[\"val_loss\"], label=\"test_loss\")\n",
        "plt.plot(hist_l2.history[\"accuracy\"],label = \"train_accuracy\")\n",
        "plt.plot(hist_l2.history[\"val_accuracy\"],label = 'test_accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "itA33HF9iD0r",
        "outputId": "71afb1ab-178f-4e6d-a4fc-6941a22f8613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion:**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "*   The accuracy for Logistic Regression: 92.61%\n",
        "*   The accuracy for Neural Networks: 99.95%\n",
        "*   The accuracy for Neural Networks with L2 Regularization and DropOut: 97.24%\n"
      ],
      "metadata": {
        "id": "qodYxCTlvYGg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TEl6dIrfsrkO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}